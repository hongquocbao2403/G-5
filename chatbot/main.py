from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
import os
from dotenv import load_dotenv
import openai

# ğŸ‘‰ Load API Key tá»« .env
load_dotenv()
api_key = os.getenv("KEY_API_GPT")

if not api_key:
    raise ValueError("âŒ Lá»–I: API Key khÃ´ng tÃ¬m tháº¥y! Kiá»ƒm tra láº¡i .env")

# âœ… ÄÃºng cÃº phÃ¡p OpenAI API >= 1.0.0
client = openai.OpenAI(api_key=api_key)

# ğŸ‘‰ Khá»Ÿi táº¡o FastAPI
app = FastAPI()

# âœ… Cáº¥u hÃ¬nh CORS cho phÃ©p truy cáº­p tá»« trÃ¬nh duyá»‡t
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ… Model nháº­n dá»¯ liá»‡u tá»« ngÆ°á»i dÃ¹ng
class ChatRequest(BaseModel):
    message: str

# âœ… Endpoint kiá»ƒm tra káº¿t ná»‘i
@app.get("/")
def read_root():
    return {"message": "âœ… API Chatbot Thá»i trang GPT-4o-mini Ä‘ang cháº¡y!"}

# âœ… Endpoint chatbot
@app.post("/chatbot")
async def chatbot_response(request: ChatRequest):
    user_message = request.message.strip()

    if not user_message:
        raise HTTPException(status_code=400, detail="âŒ Tin nháº¯n khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng!")

    try:
        # ğŸ‘‰ Gá»i OpenAI API vá»›i cÃº phÃ¡p má»›i
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Báº¡n lÃ  má»™t nghá»‡ sÄ© AI chuyÃªn vá» thá»i trang."},
                {"role": "user", "content": user_message}
            ]
        )

        bot_reply = response.choices[0].message.content.strip()

    except Exception as e:
        bot_reply = f"ğŸš¨ ÄÃ£ xáº£y ra lá»—i: {str(e)}"

    return {"response": bot_reply}

# âœ… Cháº¡y trá»±c tiáº¿p tá»« file main.py
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="127.0.0.1", port=8000, reload=True)


